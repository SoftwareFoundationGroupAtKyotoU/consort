\section{Inference and Extensions}
\label{sec:infr}
We now briefly describe the inference algorithm implemented in
our tool \name. We sketch some extensions needed to type more
interesting programs and close with a discussion of limitations of
our prototype.

\subsection{Inference}
Our tool first runs a standard, simple type inference
algorithm to generate type templates for every function parameter
type, return type, and for every live variable at each program point.
For a variable $x$ of simple type $[[ST]] ::= [[int]] \mid [[ST ref]]$
at program point $p$ \name generates a type template $[[ [ST](x,0,pp) ]]$
as follows:
\begin{align*}
  [[ [int](x,nn,pp) ]] = [[{nu:int|ph(x,nn,pp)[FV pp]}]] && [[ [ST ref](x,nn,pp) ]] = [[ [ST](x,nn+1,pp) ref r[x,nn,pp] ]]
\end{align*}
where $[[ph(x,nn,pp)[FV pp] ]]$ denotes a fresh relation symbol
whose arguments are $[[nu]]$ and the free variables of simple type $[[int]]$
at program point $[[pp]]$ (denoted $[[FV pp]]$), and $[[r[x,nn,pp] ]]$ is a
fresh ownership variable. For each function definition $[[f]]$,
there are two synthetic program points, $[[f st]]$ and $[[f end]]$
for the beginning and end respectively of the function.
At both points, \name generates type template for each argument, where $[[FV f st]]$
and $[[FV f end]]$ are the names of integer typed parameters.
Further, at $[[f end]]$, \name generates a type template for the return
value using the synthetic variable name $\RETVAR$.
We write $[[ G@pp ]]$ to indicate the type environment at point $[[pp]]$,
where every variable is mapped to the appropriate type template.
Then $[[ [G@pp] ]]$ is equivalent to:
\[
  [[ /\ { x in FV pp } [x/nu]ph(x,0,pp)[FV pp] ]]
\]

When generating these type templates, our implementation
also generates ownership well-formedness constraints. Specifically,
for a type template of the form $[[ {nu:int|ph(x,nn+1,pp)[FV pp]} ref r[x,nn,pp] ]]$
\name emits the constraint: $[[ r[x,nn,pp] = 0 ==> ph(x,nn+1,pp)[FV pp] ]]$
and for a type template $[[ (T ref r[x,nn+1,pp]) ref r[x,nn,pp] ]]$
\name emits the constrain $[[ r[x,nn,pp] = 0 ==> r[x,nn+1,pp] = 0 ]]$.

\name then walks the program, generating constraints between
relation symbols and ownership variables according to
the typing rules. These constraints take three forms, ownership
constraints, subtyping constraints, and assertion constraints.
Ownership constraints are simple linear (in)equalities over ownership variables
and constants, according to conditions imposed by the typing
rules. For example, if variable $[[x]]$ has the type template
$[[T ref r[x,0,pp] ]]$ for the expression $[[ x := y; e ]]$ at point
$[[pp]]$, \name generates the constraint $[[r[x,0,pp] = 1]]$.

 \name emits subtyping constraints between the relation symbols
at related program points according to the rules of the type system.
For example, consider the let binding $[[ let x = y in e ]]$
at program point $[[pp]]$, where $[[e]]$ is at program point $[[pp']]$, and $[[x]]$ has simple type
$[[int ref]]$.
\name generates the following subtyping constraint:
\[
  [[ [G@pp] /\ ph(y,1,pp)[FV pp] ==> ph(y,1,pp')[FV pp'] /\ ph(x,1,pp')[FV pp'] ]]
\]
in addition to the ownership constraint $[[r[y,0,pp] = r[y,0,pp'] + r[x,0,pp'] ]]$.

Finally for each \lstinline[mathescape]{assert($[[ph]]$)} in the program \name emits an assertion
constraint of the form: $[[ [G@pp] ==> ph ]]$
which requires the refinements on integer typed variables
in scope are sufficient to prove $[[ph]]$.

\subsubsection{Solving}
The result of the above process are two systems of constraints; linear real arithmetic constraints over
ownership variables and constrained Horn clauses over the refinement relations.
These systems are not independent; the relation constraints may mention the value
of ownership variables due to the well-formedness constraints described above.
The ownership constraints are first solved with Z3 \cite{de2008z3}.
When solving, we constrain the solver to maximize the number of non-zero ownership
variables; this ensures minimal
refinement information is lost due to $0$ ownerships.
The inferred values for ownership variables are then substituted into the
constrained Horn clauses, and the resulting system is checked
for satisfiability with an off-the-shelf constrained Horn clause solver.
Our implementation generates the above constraints in the industry standard
SMT-Lib2 format \cite{BarFT-SMTLIB}, so any solver that understands
this format can be used as a backend for \name. Our implementation
currently supports Spacer \cite{komuravelli2013automatic} (part of the Z3 solver \cite{de2008z3}),
HoICE \cite{champion2018hoice}, and Eldarica \cite{rummer2013disjunctive}
(adding a new backend requires only a handful of lines of ML glue code).

\subsubsection{Encoding Context Sensitivity}
To make inference tractable, we require the user to fix \emph{a
  priori} the maximum length of prefix queries to a constant $k$ (this
choice is easily controlled with a command line parameter to our tool). We
supplement the free variables used in every predicate with a set of
context variables $[[CC k]]$; these variables are assumed to not
overlap with any program variables.

\name then uses these variables to infer context sensitive
refinements as follows. Consider a function call
$[[ let x = f l (y1,,yn) in e ]]$ at point $[[pp]]$
where $[[e]]$ is at point $[[pp']]$.
\name generates the following constraint for a refinement
$[[ph(yi,nn,pp)[FV pp U CC k] ]]$ which occurs in the type template of $[[yi]]$:
\begin{align*}
  & [[ ph(yi,nn,pp)[FV pp U CC k] ==> vsub [l/c0][c1/c2] ,, [ck-1/ck] ph(xi,nn,f st)[FV f st U CC k] ]] \\
  & [[ vsub [l/c0][c1/c2],,[ck-1/ck] ph(xi,nn,f end)[FV f end U CC k] ==> ph(yi,nn,pp')[FV pp' U CC k]  ]] \\
  & [[ vsub = [y1/x1] ,, [yn/xn] ]]
\end{align*}
In the above, $[[ [l/c0][c1/c2],,[ck-1/ck] ]]$ plays the role of
$[[ csub ]]$ in the \rn{T-Call} rule. The above constraint effectively
constrains the value of $[[c0]]$ within the body of the function $[[f]]$.
If $[[f]]$ calls another function $[[g]]$, the above rule
propagates this value of $[[c0]]$ to $[[c1]]$ within $[[g]]$ and so on.
The solver may then instantiate relation symbols with predicates
that are conditional over the values of $[[ci]]$.

\subsection{Extensions}
We now describe some extensions to our core language supported within
our implementation.

\paragraph{Primitive Operations}
As defined in \Cref{sec:prelim}, our language can compare integers to zero and load
and store them from memory, but can perform no meaningful computation
over these numbers. To promote the flexibility of our type system and simplify
our soundness statement, we do not
fix a set of primitive operations and their static semantics.
Instead, we assume any set of primitive operations
used in a program are given sound function types in $[[Th]]$.
For example, under the assumption that $+$ has its usual semantics
and the underlying logic supports $+$, we can give $+$ the type
$[[A <x:top, y:top> -> <x:top, y:top|{nu:int|nu = x + y}>]]$.
Interactions with a nondeterministic environment
or unknown program inputs can then be modeled with a primitive
that returns integers with refinement $[[Top]]$.


\paragraph{Dependent Tuples}
Our implementation supports types of the form:
$[[ (x1: T1 ,, xn: Tn) ]]$, where $[[xi]]$ is free within $[[Tj]]$
($j\neq i$) if $[[Ti]]$ is not a reference type. For example,
$[[ (x: {nu:int|Top}, y:{nu:int|nu>x})]]$ is the type of tuples whose
second element is strictly greater than the first. We also extend
the language with tuple constructors as a new value form, and
let bindings with tuple patterns as the LHS.
Our language does \emph{not} include
explicit projection operators to ensure refinements types of tuple elements
are well-formed with respect to free variables.

The extension to type checking is relatively straightforward; the only
significant extensions are to the subtyping rules.
Specifically, the subtyping check for a tuple element
$[[xi:Ti]]$ is performed in a type environment elaborated with
types of other tuple elements.
The extension to type inference is also
straightforward; the free variables for a
predicate symbol include any enclosing dependent tuple names
and the environment in subtyping constraints are likewise
adjusted.

\paragraph{Recursive Types}
Our language also supports some unbounded heap structures via recursive
reference types. To keep inference tractable, we forbid nested
recursive types, multiple instances of a type variable, \AI{What are they?}
and fix the shape of refinements that occur within a
recursive type. For recursive refinements that fit the
above restriction, our approach for refinements
is broadly similar to that in \cite{kawaguchi2009type}, and we use
the ownership scheme of \cite{suenaga2009fractional} for handling
ownership. We first use simple type inference
to infer the shape of the recursive types, and automatically insert
fold/unfold annotations into the source program. As in
\cite{kawaguchi2009type},
the refinements within an unfolding of a recursive type may refer to
dependent tuple names bound by the enclosing type. These recursive
types can therefore express the invariant, e.g., of a (mutable)
sorted list. Adapting the approach in \cite{suenaga2009fractional},
all recursive types are unfolded once before assigning ownership variables.
Further unfoldings simply copy existing ownership variables.

As in Java or C++, our language does not support sum types,
and thus any instantiation of a recursive type must use a null pointer.
Our implementation therefore supports an \lstinline{ifnull} construct
and a distinguished null constant. Our implementation allows any refinement
to hold for the null constant, including $\bot$. Currently, our implementation
currently does \emph{not} detect null pointer dereferences, and all soundness
guarantees are made modulo freedom of null dereferences. As $[[ [G] ]]$
omits the refinements on reference types, these refinements do not affect
the verification of programs free of null pointer dereferences.
\JT{This still seems insufficient...}

\paragraph{Arrays}
Our implementation supports arrays of integers. Each array is given
an ownership describing the ownership of memory allocated for the entire array.
The array type contains two refinements: the first refines the length of the array itself,
and the second refines the entire array contents.
The content refinement predicate may refer to a symbolic index variable,
for precise, per-index refinements. At reads and writes to the
array \name instantiates the refinement's symbolic index variable with
the concrete index variable used at the read/write.

As in \cite{suenaga2009fractional}, our restriction to arrays of integers
stems from the difficulty of ownership inference. Sound handling
of pointer arrays requires index-wise tracking of ownerships which
significantly complicates automated inference. We leave supporting
arrays of pointers to future work.

\subsection{Limitations}
Our current approach is not complete; there are safe programs that will be
rejected by our type system. As mentioned in \Cref{sec:types}, our well-formedness
condition forbids refinements that refer to memory locations. As a result,
\name cannot in general express, e.g., that the contents of two references are equal.
Further, like other verification techniques built upon automated theorem provers,
our type system is limited by the restriction to a decidable, first-order logic for
refinement predicates. For example, from the undecidability of non-linear integer arithmetic,
\name cannot verify a program that requires a proof of Fermat's last theorem.
\name also does not support conditional or context-sensitive ownerships, and therefore
cannot in general verify programs that have conditional aliasing relationships
or only conditionally mutate a reference.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

%  LocalWords:  formedness ownerships satisfiability dereferences
%  LocalWords:  provers
